{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CLEF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A53-wisWwdgH",
        "outputId": "134dea37-1d3e-411d-89a1-e5879f1f2fa9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_GUKBEYxQf5",
        "outputId": "a83afb30-4998-4a46-8489-f2aedf1df7f4"
      },
      "source": [
        "!ls /content/drive/MyDrive/Colab\\ Notebooks/ftp"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "task2  task3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_---Zod1z7Hu"
      },
      "source": [
        "!pip3 install transformers\n",
        "!pip3 install tensorflow\n",
        "!pip3 install numpy\n",
        "!pip3 install scikit-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_krlStdxbFp",
        "outputId": "3f4b5369-080d-4e9b-c117-a09aecfeb1b4"
      },
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import glob\n",
        "import re\n",
        "\n",
        "def get_xml_tag_contents(xml_str, tag):\n",
        "    open_tag = f\"<{tag}>\"\n",
        "    close_tag = f\"</{tag}>\"\n",
        "    open_tag_end = xml_str.find(open_tag)+len(open_tag)\n",
        "    close_tag_start = xml_str.find(close_tag, open_tag_end)\n",
        "    return xml_str[open_tag_end:close_tag_start], xml_str[close_tag_start+len(close_tag):]\n",
        "\n",
        "def parse_subject_xml(filename):\n",
        "    with open(filename, \"r+\") as f:\n",
        "        xml_str = f.read()\n",
        "    xml_str, _ = get_xml_tag_contents(xml_str, \"INDIVIDUAL\")\n",
        "    id_str, xml_str = get_xml_tag_contents(xml_str, \"ID\")\n",
        "    subjectId = id_str.strip()\n",
        "    writings = []\n",
        "    while (xml_str.strip() != \"\"):\n",
        "        writing = {}\n",
        "        writing_str, xml_str = get_xml_tag_contents(xml_str, \"WRITING\")\n",
        "        \n",
        "        title_str, writing_str = get_xml_tag_contents(writing_str, \"TITLE\")\n",
        "        writing[\"TITLE\"] = title_str.strip()\n",
        "        date_str, writing_str = get_xml_tag_contents(writing_str, \"DATE\")\n",
        "        writing[\"DATE\"] = date_str.strip()\n",
        "        info_str, writing_str = get_xml_tag_contents(writing_str, \"INFO\")\n",
        "        writing[\"INFO\"] = info_str.strip()\n",
        "        text_str, writing_str = get_xml_tag_contents(writing_str, \"TEXT\")\n",
        "        writing[\"TEXT\"] = text_str.strip()\n",
        "\n",
        "        writings.append(writing)\n",
        "    return subjectId, writings\n",
        "\n",
        "\n",
        "training_users = {}\n",
        "# Add training subjects & posts\n",
        "filepath = f\"/content/drive/MyDrive/Colab Notebooks/ftp/task3/training/*/subject*.xml\"\n",
        "filenames = glob.glob(filepath)\n",
        "for filename in filenames:\n",
        "    subjectId, writings = parse_subject_xml(filename)\n",
        "    if subjectId == \"\" or writings == []:\n",
        "        continue\n",
        "    year = re.findall(\"/content/drive/MyDrive/Colab\\ Notebooks/ftp/task3/training/([0-9]{4})/subject[0-9]*.xml\", filename)[0]\n",
        "    subjectId = f\"{year}-{subjectId}\"\n",
        "    training_users[subjectId] = {\"WRITINGS\": writings}\n",
        "# Add training subject responses\n",
        "filepath = f\"/content/drive/MyDrive/Colab Notebooks/ftp/task3/training/*/Depression Questionnaires_anon.txt\"\n",
        "filenames = glob.glob(filepath)\n",
        "for filename in filenames:\n",
        "    year = re.findall(\"/content/drive/MyDrive/Colab Notebooks/ftp/task3/training/([0-9]{4})/Depression Questionnaires_anon.txt\", filename)[0]\n",
        "    with open(filename, \"r+\") as f:\n",
        "        user_responses = [line.strip().split(\"\\t\") for line in f.readlines() if line.strip != \"\"]\n",
        "    for user_response in user_responses:\n",
        "        subjectId = f\"{year}-{user_response[0]}\"\n",
        "        responses = user_response[1:]\n",
        "        training_users[subjectId]['RESPONSES'] = responses\n",
        "print(f\"Loaded {len(training_users)} training users\")\n",
        "\n",
        "# Add testing subjects & posts\n",
        "testing_users = {}\n",
        "filepath = f\"/content/drive/MyDrive/Colab Notebooks/ftp/task3/data/2021/erisk2021-T3_Subject*.xml\"\n",
        "filenames = glob.glob(filepath)\n",
        "for filename in filenames:\n",
        "    subjectId, writings = parse_subject_xml(filename)\n",
        "    if subjectId == \"\" or writings == []:\n",
        "        continue\n",
        "    testing_users[subjectId] = {\"WRITINGS\": writings, \"RESPONSES\": []}\n",
        "print(f\"Loaded {len(testing_users)} testing users\")\n",
        "\n",
        "# TODO: make a model & add predictions to test users\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Output test subject responses\n",
        "filepath = f\"/content/drive/MyDrive/Colab Notebooks/ftp/task3/results/Depression Questionnaires_anon.txt\"\n",
        "with open(filepath, \"w+\") as f:\n",
        "    f.write('\\n'.join([user + ' ' + ' '.join(testing_users[user]['RESPONSES']) for user in testing_users]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 90 training users\n",
            "Loaded 80 testing users\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXjtAkOmGIu3",
        "outputId": "d018cf71-b9bd-4310-d629-f8db27ab396a"
      },
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize  \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "nltk.download('words')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "words = set(nltk.corpus.words.words())\n",
        "text = []\n",
        "responses=[]\n",
        "t=\"\"\n",
        "for key in training_users:\n",
        "  \n",
        "  key_response = []\n",
        "  for i, val in enumerate(training_users[key][\"RESPONSES\"]):\n",
        "    if val == '0':\n",
        "      if i!=15 and i!=17:\n",
        "        one_hot = [1,0,0,0]\n",
        "      else:\n",
        "        one_hot = [1,0,0,0,0,0,0]\n",
        "    elif val =='1':\n",
        "        one_hot = [0,1,0,0]\n",
        "    elif val == '2':\n",
        "        one_hot = [0,0,1,0]\n",
        "    elif val == '3':\n",
        "        one_hot = [0,0,0,1]\n",
        "    elif val == '1a':\n",
        "        one_hot = [0,1,0,0,0,0,0]\n",
        "    elif val =='1b':\n",
        "        one_hot = [0,0,1,0,0,0,0]\n",
        "    elif val =='2a':\n",
        "        one_hot = [0,0,0,1,0,0,0]\n",
        "    elif val =='2b':\n",
        "        one_hot = [0,0,0,0,1,0,0]\n",
        "    elif val =='3a':\n",
        "        one_hot = [0,0,0,0,0,1,0]\n",
        "    elif val =='3b':\n",
        "        one_hot = [0,0,0,0,0,0,1]\n",
        "\n",
        "    key_response.append(np.asarray(one_hot))\n",
        "\n",
        "  for dic in training_users[key][\"WRITINGS\"]:\n",
        "    no_url = re.sub(r'http\\S+', '', dic[\"TITLE\"]+dic[\"TEXT\"])\n",
        "    phrase = re.sub(r\"won\\'t\", \"not\", no_url)\n",
        "    phrase = re.sub(r\"can\\'t\", \"not\", phrase)\n",
        "    phrase = re.sub(r\"isn\\'t\", \"not\", phrase)\n",
        "    phrase = re.sub(r\"aren\\'t\", \"not\", phrase)\n",
        "    phrase = re.sub(r\"don\\'t\", \"not\", phrase)\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    no_nonascill = re.sub(r'[^\\x00-\\x7F]+',' ', phrase)\n",
        "    lowercase = no_nonascill.lower()\n",
        "    clean = re.sub('\\W+',' ', lowercase )\n",
        "    p_stemmer = PorterStemmer()\n",
        "    nltk_tokenList = word_tokenize(clean)\n",
        "    #Stemming\n",
        "    nltk_stemedList = []\n",
        "    for word in nltk_tokenList:\n",
        "        nltk_stemedList.append(p_stemmer.stem(word))\n",
        "        #nltk_stemedList.append(s_stemmer.stem(word))\n",
        "    \n",
        "    #Lemmatization\n",
        "    wordnet_lemmatizer = WordNetLemmatizer()\n",
        "    nltk_lemmaList = []\n",
        "    for word in nltk_stemedList:\n",
        "        nltk_lemmaList.append(wordnet_lemmatizer.lemmatize(word))\n",
        "\n",
        "    #Filter stopword\n",
        "    filtered_sentence = []  \n",
        "    nltk_stop_words = set(stopwords.words(\"english\"))\n",
        "    for w in nltk_lemmaList:  \n",
        "        if w not in nltk_stop_words:  \n",
        "            filtered_sentence.append(w)  \n",
        "\n",
        "    #Removing Punctuation\n",
        "    punctuations=\"?:!.,;\"\n",
        "    for word in filtered_sentence:\n",
        "        if word in punctuations:\n",
        "            filtered_sentence.remove(word)\n",
        "    \n",
        "    t = \"\"\n",
        "    for word in filtered_sentence:\n",
        "      if t == \"\":\n",
        "        t = t + word\n",
        "      else:\n",
        "        t = t + \" \" + word\n",
        "    text.append(t)\n",
        "    responses.append(key_response)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iZJQBo5z1y2"
      },
      "source": [
        "from transformers import TFBertModel,  BertConfig, BertTokenizerFast\n",
        "from tensorflow.keras.layers import Input, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPzIvliiITSz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "outputId": "6e40ee61-fb5d-4b6c-bd45-ac51baef806e"
      },
      "source": [
        "nparr=[[]]\n",
        "for i in range(len(text)):\n",
        "\n",
        "  arr = np.asarray([[text[i]]])\n",
        "  arr = np.append( arr, [responses[i]])\n",
        "  nparr.append(arr)\n",
        "nparr\n",
        "df = pd.DataFrame(nparr, columns=['Text', 'Q1','Q2','Q3','Q4','Q5','Q6','Q7','Q8','Q9','Q10','Q11','Q12','Q13','Q14','Q15','Q16','Q17','Q18','Q19','Q20','Q21'])\n",
        "df = df.drop(df.index[0])\n",
        "df"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order, subok=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Q1</th>\n",
              "      <th>Q2</th>\n",
              "      <th>Q3</th>\n",
              "      <th>Q4</th>\n",
              "      <th>Q5</th>\n",
              "      <th>Q6</th>\n",
              "      <th>Q7</th>\n",
              "      <th>Q8</th>\n",
              "      <th>Q9</th>\n",
              "      <th>Q10</th>\n",
              "      <th>Q11</th>\n",
              "      <th>Q12</th>\n",
              "      <th>Q13</th>\n",
              "      <th>Q14</th>\n",
              "      <th>Q15</th>\n",
              "      <th>Q16</th>\n",
              "      <th>Q17</th>\n",
              "      <th>Q18</th>\n",
              "      <th>Q19</th>\n",
              "      <th>Q20</th>\n",
              "      <th>Q21</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>im sorri youv neg experi im support ever need ...</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>scratch top wrist</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>opinion high school anxietyi suffer exam cente...</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>im sorri hear wish could give warm comfort hug...</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>hi im head bed plea feel free spill thought ch...</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46499</th>\n",
              "      <td>remu romulu learn latin class far understood m...</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46500</th>\n",
              "      <td>would dismiss belgium quit soon forget footbal...</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46501</th>\n",
              "      <td>fair think would kill ourselv need outsid inte...</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46502</th>\n",
              "      <td>veri true soon go flander notic differ differ ...</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46503</th>\n",
              "      <td>thing move quit popul countri luxembourg live ...</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>46503 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    Text  ...           Q21\n",
              "1      im sorri youv neg experi im support ever need ...  ...  [0, 1, 0, 0]\n",
              "2                                      scratch top wrist  ...  [0, 1, 0, 0]\n",
              "3      opinion high school anxietyi suffer exam cente...  ...  [0, 1, 0, 0]\n",
              "4      im sorri hear wish could give warm comfort hug...  ...  [0, 1, 0, 0]\n",
              "5      hi im head bed plea feel free spill thought ch...  ...  [0, 1, 0, 0]\n",
              "...                                                  ...  ...           ...\n",
              "46499  remu romulu learn latin class far understood m...  ...  [1, 0, 0, 0]\n",
              "46500  would dismiss belgium quit soon forget footbal...  ...  [1, 0, 0, 0]\n",
              "46501  fair think would kill ourselv need outsid inte...  ...  [1, 0, 0, 0]\n",
              "46502  veri true soon go flander notic differ differ ...  ...  [1, 0, 0, 0]\n",
              "46503  thing move quit popul countri luxembourg live ...  ...  [1, 0, 0, 0]\n",
              "\n",
              "[46503 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Eqnv-M_33Ua",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "a33fd9b5-2a36-412b-a7e3-111731a12c0f"
      },
      "source": [
        "\n",
        "df, df_test = train_test_split(df, train_size = 38146, shuffle=False)\n",
        "df"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Q1</th>\n",
              "      <th>Q2</th>\n",
              "      <th>Q3</th>\n",
              "      <th>Q4</th>\n",
              "      <th>Q5</th>\n",
              "      <th>Q6</th>\n",
              "      <th>Q7</th>\n",
              "      <th>Q8</th>\n",
              "      <th>Q9</th>\n",
              "      <th>Q10</th>\n",
              "      <th>Q11</th>\n",
              "      <th>Q12</th>\n",
              "      <th>Q13</th>\n",
              "      <th>Q14</th>\n",
              "      <th>Q15</th>\n",
              "      <th>Q16</th>\n",
              "      <th>Q17</th>\n",
              "      <th>Q18</th>\n",
              "      <th>Q19</th>\n",
              "      <th>Q20</th>\n",
              "      <th>Q21</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>im sorri youv neg experi im support ever need ...</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>scratch top wrist</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>opinion high school anxietyi suffer exam cente...</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>im sorri hear wish could give warm comfort hug...</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>hi im head bed plea feel free spill thought ch...</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 0, 1]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 0, 1, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38142</th>\n",
              "      <td>beauti soft calm</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38143</th>\n",
              "      <td>found idea sinc wear nail polish pretti much t...</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38144</th>\n",
              "      <td>start bullet journal three week ago lot inspir...</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38145</th>\n",
              "      <td>okay like thursday either</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38146</th>\n",
              "      <td>mine cover europ becaus onli rest world twice ...</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[0, 1, 0, 0]</td>\n",
              "      <td>[1, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>38146 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    Text  ...           Q21\n",
              "1      im sorri youv neg experi im support ever need ...  ...  [0, 1, 0, 0]\n",
              "2                                      scratch top wrist  ...  [0, 1, 0, 0]\n",
              "3      opinion high school anxietyi suffer exam cente...  ...  [0, 1, 0, 0]\n",
              "4      im sorri hear wish could give warm comfort hug...  ...  [0, 1, 0, 0]\n",
              "5      hi im head bed plea feel free spill thought ch...  ...  [0, 1, 0, 0]\n",
              "...                                                  ...  ...           ...\n",
              "38142                                   beauti soft calm  ...  [1, 0, 0, 0]\n",
              "38143  found idea sinc wear nail polish pretti much t...  ...  [1, 0, 0, 0]\n",
              "38144  start bullet journal three week ago lot inspir...  ...  [1, 0, 0, 0]\n",
              "38145                          okay like thursday either  ...  [1, 0, 0, 0]\n",
              "38146  mine cover europ becaus onli rest world twice ...  ...  [1, 0, 0, 0]\n",
              "\n",
              "[38146 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbudJbWNrZQa"
      },
      "source": [
        "Q1=[]\n",
        "Q2=[]\n",
        "Q3=[]\n",
        "Q4=[]\n",
        "Q5=[]\n",
        "Q6=[]\n",
        "Q7=[]\n",
        "Q8=[]\n",
        "Q9=[]\n",
        "Q10=[]\n",
        "Q11=[]\n",
        "Q12=[]\n",
        "Q13=[]\n",
        "Q14=[]\n",
        "Q15=[]\n",
        "Q16=[]\n",
        "Q17=[]\n",
        "Q18=[]\n",
        "Q19=[]\n",
        "Q20=[]\n",
        "Q21=[]\n",
        "for i in df[\"Q1\"]:\n",
        "  Q1.append(i)\n",
        "for i in df[\"Q2\"]:\n",
        "  Q2.append(i)\n",
        "for i in df[\"Q3\"]:\n",
        "  Q3.append(i)\n",
        "for i in df[\"Q4\"]:\n",
        "  Q4.append(i)\n",
        "for i in df[\"Q5\"]:\n",
        "  Q5.append(i)\n",
        "for i in df[\"Q6\"]:\n",
        "  Q6.append(i)\n",
        "for i in df[\"Q7\"]:\n",
        "  Q7.append(i)\n",
        "for i in df[\"Q8\"]:\n",
        "  Q8.append(i)\n",
        "for i in df[\"Q9\"]:\n",
        "  Q9.append(i)\n",
        "for i in df[\"Q10\"]:\n",
        "  Q10.append(i)\n",
        "for i in df[\"Q11\"]:\n",
        "  Q11.append(i)\n",
        "for i in df[\"Q12\"]:\n",
        "  Q12.append(i)\n",
        "for i in df[\"Q13\"]:\n",
        "  Q13.append(i)\n",
        "for i in df[\"Q14\"]:\n",
        "  Q14.append(i)\n",
        "for i in df[\"Q15\"]:\n",
        "  Q15.append(i)\n",
        "for i in df[\"Q16\"]:\n",
        "  Q16.append(i)\n",
        "for i in df[\"Q17\"]:\n",
        "  Q17.append(i)\n",
        "for i in df[\"Q18\"]:\n",
        "  Q18.append(i)\n",
        "for i in df[\"Q19\"]:\n",
        "  Q19.append(i)\n",
        "for i in df[\"Q20\"]:\n",
        "  Q20.append(i)\n",
        "for i in df[\"Q21\"]:\n",
        "  Q21.append(i)\n",
        "Q1 = np.asarray(Q1)\n",
        "Q2 = np.asarray(Q2)\n",
        "Q3 = np.asarray(Q3)\n",
        "Q4 = np.asarray(Q4)\n",
        "Q5 = np.asarray(Q5)\n",
        "Q6 = np.asarray(Q6)\n",
        "Q7 = np.asarray(Q7)\n",
        "Q8 = np.asarray(Q8)\n",
        "Q9 = np.asarray(Q9)\n",
        "Q10 = np.asarray(Q10)\n",
        "Q11 = np.asarray(Q11)\n",
        "Q12 = np.asarray(Q12)\n",
        "Q13 = np.asarray(Q13)\n",
        "Q14 = np.asarray(Q14)\n",
        "Q15 = np.asarray(Q15)\n",
        "Q16 = np.asarray(Q16)\n",
        "Q17 = np.asarray(Q17)\n",
        "Q18 = np.asarray(Q18)\n",
        "Q19 = np.asarray(Q19)\n",
        "Q20 = np.asarray(Q20)\n",
        "Q21 = np.asarray(Q21)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl4fqIJ_reB3"
      },
      "source": [
        "Q1_test=[]\n",
        "Q2_test=[]\n",
        "Q3_test=[]\n",
        "Q4_test=[]\n",
        "Q5_test=[]\n",
        "Q6_test=[]\n",
        "Q7_test=[]\n",
        "Q8_test=[]\n",
        "Q9_test=[]\n",
        "Q10_test=[]\n",
        "Q11_test=[]\n",
        "Q12_test=[]\n",
        "Q13_test=[]\n",
        "Q14_test=[]\n",
        "Q15_test=[]\n",
        "Q16_test=[]\n",
        "Q17_test=[]\n",
        "Q18_test=[]\n",
        "Q19_test=[]\n",
        "Q20_test=[]\n",
        "Q21_test=[]\n",
        "for i in df_test[\"Q1\"]:\n",
        "  Q1_test.append(i)\n",
        "for i in df_test[\"Q2\"]:\n",
        "  Q2_test.append(i)\n",
        "for i in df_test[\"Q3\"]:\n",
        "  Q3_test.append(i)\n",
        "for i in df_test[\"Q4\"]:\n",
        "  Q4_test.append(i)\n",
        "for i in df_test[\"Q5\"]:\n",
        "  Q5_test.append(i)\n",
        "for i in df_test[\"Q6\"]:\n",
        "  Q6_test.append(i)\n",
        "for i in df_test[\"Q7\"]:\n",
        "  Q7_test.append(i)\n",
        "for i in df_test[\"Q8\"]:\n",
        "  Q8_test.append(i)\n",
        "for i in df_test[\"Q9\"]:\n",
        "  Q9_test.append(i)\n",
        "for i in df_test[\"Q10\"]:\n",
        "  Q10_test.append(i)\n",
        "for i in df_test[\"Q11\"]:\n",
        "  Q11_test.append(i)\n",
        "for i in df_test[\"Q12\"]:\n",
        "  Q12_test.append(i)\n",
        "for i in df_test[\"Q13\"]:\n",
        "  Q13_test.append(i)\n",
        "for i in df_test[\"Q14\"]:\n",
        "  Q14_test.append(i)\n",
        "for i in df_test[\"Q15\"]:\n",
        "  Q15_test.append(i)\n",
        "for i in df_test[\"Q16\"]:\n",
        "  Q16_test.append(i)\n",
        "for i in df_test[\"Q17\"]:\n",
        "  Q17_test.append(i)\n",
        "for i in df_test[\"Q18\"]:\n",
        "  Q18_test.append(i)\n",
        "for i in df_test[\"Q19\"]:\n",
        "  Q19_test.append(i)\n",
        "for i in df_test[\"Q20\"]:\n",
        "  Q20_test.append(i)\n",
        "for i in df_test[\"Q21\"]:\n",
        "  Q21_test.append(i)\n",
        "Q1_test = np.asarray(Q1_test)\n",
        "Q2_test = np.asarray(Q2_test)\n",
        "Q3_test = np.asarray(Q3_test)\n",
        "Q4_test = np.asarray(Q4_test)\n",
        "Q5_test = np.asarray(Q5_test)\n",
        "Q6_test = np.asarray(Q6_test)\n",
        "Q7_test = np.asarray(Q7_test)\n",
        "Q8_test = np.asarray(Q8_test)\n",
        "Q9_test = np.asarray(Q9_test)\n",
        "Q10_test = np.asarray(Q10_test)\n",
        "Q11_test = np.asarray(Q11_test)\n",
        "Q12_test = np.asarray(Q12_test)\n",
        "Q13_test = np.asarray(Q13_test)\n",
        "Q14_test = np.asarray(Q14_test)\n",
        "Q15_test = np.asarray(Q15_test)\n",
        "Q16_test = np.asarray(Q16_test)\n",
        "Q17_test = np.asarray(Q17_test)\n",
        "Q18_test = np.asarray(Q18_test)\n",
        "Q19_test = np.asarray(Q19_test)\n",
        "Q20_test = np.asarray(Q20_test)\n",
        "Q21_test = np.asarray(Q21_test)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63mx3y880ZfE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f51aa67-0b46-4909-c0cc-38d29cc2c487"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# for i in range(1,22):\n",
        "#     df['Q'+str(i)+'_label'] = pd.Categorical(df['Q'+str(i)])\n",
        "#     df['Q'+str(i)] = df['Q'+str(i)+'_label'].cat.codes\n",
        "\n",
        "model_name = 'bert-base-uncased'\n",
        "max_length = 128\n",
        "\n",
        "config = BertConfig.from_pretrained(model_name)\n",
        "config.output_hidden_states = False\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n",
        "\n",
        "transformer_model = TFBertModel.from_pretrained(model_name, config = config)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3MG_Awm0aQA"
      },
      "source": [
        "bert = transformer_model.layers[0]\n",
        "\n",
        "\n",
        "input_ids = Input(shape=(max_length,), name='input_ids', dtype='int32')\n",
        "inputs = {'input_ids': input_ids}\n",
        "\n",
        "bert_model = bert(inputs)[1]\n",
        "dropout = Dropout(config.hidden_dropout_prob, name='pooled_output')\n",
        "pooled_output = dropout(bert_model, training=False)\n",
        "\n",
        "q1 = Dense(units=4, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='q1', activation='softmax')(pooled_output)\n",
        "q2 = Dense(units=4, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='q2', activation='softmax')(pooled_output)\n",
        "q3 = Dense(units=4, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='q3', activation='softmax')(pooled_output)\n",
        "q4 = Dense(units=4, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='q4', activation='softmax')(pooled_output)\n",
        "q5 = Dense(units=4, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='q5', activation='softmax')(pooled_output)\n",
        "q6 = Dense(units=4, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='q6', activation='softmax')(pooled_output)\n",
        "q7 = Dense(units=4, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='q7', activation='softmax')(pooled_output)\n",
        "q8 = Dense(units=4, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='q8', activation='softmax')(pooled_output)\n",
        "q9 = Dense(units=4, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='q9', activation='softmax')(pooled_output)\n",
        "q10 = Dense(units=4, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='q10', activation='softmax')(pooled_output)\n",
        "q11 = Dense(units=4, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='q11', activation='softmax')(pooled_output)\n",
        "q12 = Dense(units=4, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='q12', activation='softmax')(pooled_output)\n",
        "q13 = Dense(units=4, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='q13', activation='softmax')(pooled_output)\n",
        "q14 = Dense(units=4, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='q14', activation='softmax')(pooled_output)\n",
        "q15 = Dense(units=4, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='q15', activation='softmax')(pooled_output)\n",
        "q16 = Dense(units=7, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='q16', activation='softmax')(pooled_output)\n",
        "q17 = Dense(units=4, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='q17', activation='softmax')(pooled_output)\n",
        "q18 = Dense(units=7, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='q18', activation='softmax')(pooled_output)\n",
        "q19 = Dense(units=4, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='q19', activation='softmax')(pooled_output)\n",
        "q20 = Dense(units=4, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='q20', activation='softmax')(pooled_output)\n",
        "q21 = Dense(units=4, kernel_initializer=TruncatedNormal(stddev=config.initializer_range), name='q21', activation='softmax')(pooled_output)\n",
        "\n",
        "\n",
        "outputs = {'q1': q1,\n",
        "           'q2': q2,\n",
        "           'q3': q3,\n",
        "           'q4': q4,\n",
        "           'q5': q5,\n",
        "           'q6': q6,\n",
        "           'q7': q7,\n",
        "           'q8': q8,\n",
        "           'q9': q9,\n",
        "           'q10': q10,\n",
        "           'q11': q11,\n",
        "           'q12': q12,\n",
        "           'q13': q13,\n",
        "           'q14': q14,\n",
        "           'q15': q15,\n",
        "           'q16': q16,\n",
        "           'q17': q17,\n",
        "           'q18': q18,\n",
        "           'q19': q19,\n",
        "           'q20': q20,\n",
        "           'q21': q21}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIoNitYU04nM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db3d068b-113f-4100-fdc2-382cd60bb42a"
      },
      "source": [
        "model = Model(inputs=inputs, outputs=outputs, name='BERT_MultiLabel_MultiClass')\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"BERT_MultiLabel_MultiClass\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bert (TFBertMainLayer)          TFBaseModelOutputWit 109482240   input_ids[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pooled_output (Dropout)         (None, 768)          0           bert[0][1]                       \n",
            "__________________________________________________________________________________________________\n",
            "q1 (Dense)                      (None, 4)            3076        pooled_output[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "q10 (Dense)                     (None, 4)            3076        pooled_output[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "q11 (Dense)                     (None, 4)            3076        pooled_output[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "q12 (Dense)                     (None, 4)            3076        pooled_output[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "q13 (Dense)                     (None, 4)            3076        pooled_output[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "q14 (Dense)                     (None, 4)            3076        pooled_output[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "q15 (Dense)                     (None, 4)            3076        pooled_output[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "q16 (Dense)                     (None, 7)            5383        pooled_output[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "q17 (Dense)                     (None, 4)            3076        pooled_output[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "q18 (Dense)                     (None, 7)            5383        pooled_output[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "q19 (Dense)                     (None, 4)            3076        pooled_output[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "q2 (Dense)                      (None, 4)            3076        pooled_output[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "q20 (Dense)                     (None, 4)            3076        pooled_output[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "q21 (Dense)                     (None, 4)            3076        pooled_output[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "q3 (Dense)                      (None, 4)            3076        pooled_output[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "q4 (Dense)                      (None, 4)            3076        pooled_output[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "q5 (Dense)                      (None, 4)            3076        pooled_output[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "q6 (Dense)                      (None, 4)            3076        pooled_output[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "q7 (Dense)                      (None, 4)            3076        pooled_output[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "q8 (Dense)                      (None, 4)            3076        pooled_output[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "q9 (Dense)                      (None, 4)            3076        pooled_output[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 109,551,450\n",
            "Trainable params: 109,551,450\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd8SjLn11CXB"
      },
      "source": [
        "# Set an optimizer\n",
        "optimizer = Adam(\n",
        "    learning_rate=5e-5,\n",
        "    epsilon=1e-08,\n",
        "    decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "\n",
        "# Set loss and metrics\n",
        "loss = {'q1': CategoricalCrossentropy(from_logits = True), 'q2': CategoricalCrossentropy(from_logits = True),\n",
        "        'q3': CategoricalCrossentropy(from_logits = True), 'q4': CategoricalCrossentropy(from_logits = True),\n",
        "        'q5': CategoricalCrossentropy(from_logits = True), 'q6': CategoricalCrossentropy(from_logits = True),\n",
        "        'q7': CategoricalCrossentropy(from_logits = True), 'q8': CategoricalCrossentropy(from_logits = True),\n",
        "        'q9': CategoricalCrossentropy(from_logits = True), 'q10': CategoricalCrossentropy(from_logits = True),\n",
        "        'q11': CategoricalCrossentropy(from_logits = True), 'q12': CategoricalCrossentropy(from_logits = True),\n",
        "        'q13': CategoricalCrossentropy(from_logits = True), 'q14': CategoricalCrossentropy(from_logits = True),\n",
        "        'q15': CategoricalCrossentropy(from_logits = True), 'q16': CategoricalCrossentropy(from_logits = True),\n",
        "        'q17': CategoricalCrossentropy(from_logits = True), 'q18': CategoricalCrossentropy(from_logits = True),\n",
        "        'q19': CategoricalCrossentropy(from_logits = True), 'q20': CategoricalCrossentropy(from_logits = True),\n",
        "        'q21': CategoricalCrossentropy(from_logits = True)}\n",
        "\n",
        "\n",
        "metric = {'q1': CategoricalAccuracy('accuracy'), 'q2': CategoricalAccuracy('accuracy'),\n",
        "        'q3': CategoricalAccuracy('accuracy'), 'q4': CategoricalAccuracy('accuracy'),\n",
        "        'q5': CategoricalAccuracy('accuracy'), 'q6':CategoricalAccuracy('accuracy'),\n",
        "        'q7': CategoricalAccuracy('accuracy'), 'q8': CategoricalAccuracy('accuracy'),\n",
        "        'q9': CategoricalAccuracy('accuracy'), 'q10': CategoricalAccuracy('accuracy'),\n",
        "        'q11': CategoricalAccuracy('accuracy'), 'q12': CategoricalAccuracy('accuracy'),\n",
        "        'q13': CategoricalAccuracy('accuracy'), 'q14': CategoricalAccuracy('accuracy'),\n",
        "        'q15': CategoricalAccuracy('accuracy'), 'q16': CategoricalAccuracy('accuracy'),\n",
        "        'q17': CategoricalAccuracy('accuracy'), 'q18': CategoricalAccuracy('accuracy'),\n",
        "        'q19': CategoricalAccuracy('accuracy'), 'q20':CategoricalAccuracy('accuracy'),\n",
        "        'q21': CategoricalAccuracy('accuracy')}\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer = optimizer, loss = loss, metrics = metric)\n",
        "\n",
        "# Ready output data for the model\n",
        "y_q1 = Q1\n",
        "y_q2 = Q2\n",
        "y_q3 = Q3\n",
        "y_q4 = Q4\n",
        "y_q5 = Q5\n",
        "y_q6 = Q6\n",
        "y_q7 = Q7\n",
        "y_q8 = Q8\n",
        "y_q9 = Q9\n",
        "y_q10 = Q10\n",
        "y_q11 = Q11\n",
        "y_q12 = Q12\n",
        "y_q13 = Q13\n",
        "y_q14 = Q14\n",
        "y_q15 = Q15\n",
        "y_q16 = Q16\n",
        "y_q17 = Q17\n",
        "y_q18 = Q18\n",
        "y_q19 = Q19\n",
        "y_q20 = Q20\n",
        "y_q21 = Q21\n",
        "\n",
        "#Tokenize the input (takes some time)\n",
        "x = tokenizer(\n",
        "    text=df['Text'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length = max_length,\n",
        "    truncation=True,\n",
        "    padding = True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = False,\n",
        "    verbose = True)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnhQYbDrP533",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "outputId": "23591b7c-322b-4dcf-9247-2d0788eb31fd"
      },
      "source": [
        "history = model.fit(\n",
        "    x={'input_ids': x['input_ids']},\n",
        "    y={'q1': y_q1, 'q2': y_q2,\n",
        "       'q3': y_q3, 'q4': y_q4,\n",
        "       'q5': y_q5, 'q6': y_q6,\n",
        "       'q7': y_q7, 'q8': y_q8,\n",
        "       'q9': y_q9, 'q10': y_q10,\n",
        "       'q11': y_q11, 'q12': y_q12,\n",
        "       'q13': y_q13, 'q14': y_q14,\n",
        "       'q15': y_q15, 'q16': y_q16,\n",
        "       'q17': y_q17, 'q18': y_q18,\n",
        "       'q19': y_q19, 'q20': y_q20,\n",
        "       'q21': y_q21},\n",
        "    validation_split=0.3,\n",
        "    batch_size=64,\n",
        "    epochs=15)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-03f57f8714ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     epochs=15)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[64,12,128,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node BERT_MultiLabel_MultiClass/bert/encoder/layer_._11/attention/self/Softmax (defined at /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_tf_bert.py:268) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_42443]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node BERT_MultiLabel_MultiClass/bert/encoder/layer_._11/attention/self/Softmax:\n BERT_MultiLabel_MultiClass/bert/encoder/layer_._11/attention/self/Add (defined at /usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_tf_bert.py:265)\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXZYncZtiZTo"
      },
      "source": [
        "# Save Model\n",
        "model.save(\"/content/drive/MyDrive/pre15epoch_model.tf\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w3WmQ-H4Iaq"
      },
      "source": [
        "test_y_q1 = Q1_test\n",
        "test_y_q2 = Q2_test\n",
        "test_y_q3 = Q3_test\n",
        "test_y_q4 = Q4_test\n",
        "test_y_q5 = Q5_test\n",
        "test_y_q6 = Q6_test\n",
        "test_y_q7 = Q7_test\n",
        "test_y_q8 = Q8_test\n",
        "test_y_q9 = Q9_test\n",
        "test_y_q10 = Q10_test\n",
        "test_y_q11 = Q11_test\n",
        "test_y_q12 = Q12_test\n",
        "test_y_q13 = Q13_test\n",
        "test_y_q14 = Q14_test\n",
        "test_y_q15 = Q15_test\n",
        "test_y_q16 = Q16_test\n",
        "test_y_q17 = Q17_test\n",
        "test_y_q18 = Q18_test\n",
        "test_y_q19 = Q19_test\n",
        "test_y_q20 = Q20_test\n",
        "test_y_q21 = Q21_test\n",
        "\n",
        "\n",
        "test_x = tokenizer(\n",
        "    text = df_test['Text'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=max_length,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = False,\n",
        "    verbose = True)\n",
        "\n",
        "# Run evaluation\n",
        "model_eval = model.evaluate(\n",
        "    x={'input_ids': test_x['input_ids']},\n",
        "    y={'q1': test_y_q1, 'q2': test_y_q2,\n",
        "       'q3': test_y_q3, 'q4': test_y_q4,\n",
        "       'q5': test_y_q5, 'q6': test_y_q6,\n",
        "       'q7': test_y_q7, 'q8': test_y_q8,\n",
        "       'q9': test_y_q9, 'q10': test_y_q10,\n",
        "       'q11': test_y_q11, 'q12': test_y_q12,\n",
        "       'q13': test_y_q13, 'q14': test_y_q14,\n",
        "       'q15': test_y_q15, 'q16': test_y_q16,\n",
        "       'q17': test_y_q17, 'q18': test_y_q18,\n",
        "       'q19': test_y_q19, 'q20': test_y_q20,\n",
        "       'q21': test_y_q21}\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNLm3VUoIs7o"
      },
      "source": [
        "preds = model.predict(test_x[\"input_ids\"])\n",
        "preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJG6UBzSFICb"
      },
      "source": [
        "keys_test=[]\n",
        "for i,key in enumerate(training_users):\n",
        "  if i>=75:\n",
        "    keys_test.append(key)\n",
        "test_users = {key: training_users[key] for key in keys_test}\n",
        "\n",
        "count = 0\n",
        "y_preds = np.zeros([15,21])\n",
        "for i,key in enumerate(test_users):\n",
        "\n",
        "    for k in range(1,22):\n",
        "      q = preds[\"q\"+str(k)][count : count+len(test_users[key][\"WRITINGS\"])]\n",
        "      q = np.asarray(q)\n",
        "      q = np.mean(q, axis = 0)\n",
        "\n",
        "      y_preds[i][k-1] = np.argmax(q)\n",
        "    count += len(test_users[key][\"WRITINGS\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnHhmPm8i7Zw"
      },
      "source": [
        "\n",
        "y_preds = [[str(i) for i in item] for item in y_preds]\n",
        "\n",
        "for i in range(15):\n",
        "  for j in range(21):\n",
        "    val = y_preds[i][j]\n",
        "    if j!=15 and j!=17:\n",
        "      if val == '0.0':\n",
        "        y_preds[i][j] = '0'\n",
        "      elif val == '1.0':\n",
        "        y_preds[i][j] = '1'\n",
        "      elif val == '2.0':\n",
        "        y_preds[i][j] = '2'\n",
        "      elif val == '3.0':\n",
        "        y_preds[i][j]='3'\n",
        "    else:\n",
        "      if val == '0.0':\n",
        "        y_preds[i][j] = '0'\n",
        "      elif val == '1.0':\n",
        "        y_preds[i][j] = '1a'\n",
        "      elif val == '2.0':\n",
        "        y_preds[i][j] = '1b'\n",
        "      elif val == '3.0':\n",
        "        y_preds[i][j]='2a'\n",
        "      elif val == '4.0':\n",
        "        y_preds[i][j]='2b'\n",
        "      elif val == '5.0':\n",
        "        y_preds[i][j]='3a'\n",
        "      elif val == '6.0':\n",
        "        y_preds[i][j]='3b'\n",
        "\n",
        "correct_count = []\n",
        "depression_level_predicted =[]\n",
        "depression_level_truth = []\n",
        "\n",
        "for i, key in enumerate(test_users):\n",
        "  arr = test_users[key][\"RESPONSES\"]\n",
        "  count=0\n",
        "  depr_pred=0\n",
        "  depr_truth=0\n",
        "  for j in range(21):\n",
        "    depr_truth = depr_truth + int(arr[j][0])\n",
        "    depr_pred = depr_pred + int(y_preds[i][j][0])\n",
        "\n",
        "\n",
        "\n",
        "    if arr[j] == y_preds[i][j]:\n",
        "      count+=1\n",
        "\n",
        "  correct_count.append(count)\n",
        "  depression_level_truth.append(depr_truth)\n",
        "  depression_level_predicted.append(depr_pred)\n",
        "\n",
        "\n",
        "true_cat = []\n",
        "predicted_cat = []\n",
        "for i in range(15):\n",
        "  val1 = depression_level_truth[i]\n",
        "  val2 = depression_level_predicted[i]\n",
        "\n",
        "  if val1>=0 and val1<=9:\n",
        "    true_cat.append(\"minimal\")\n",
        "  elif val1>=10 and val1<=18:\n",
        "    true_cat.append(\"mild\")\n",
        "  elif val1>=19 and val1<=29:\n",
        "    true_cat.append(\"moderate\")\n",
        "  else:\n",
        "    true_cat.append(\"severe\")\n",
        "\n",
        "  if val2>=0 and val2<=9:\n",
        "    predicted_cat.append(\"minimal\")\n",
        "  elif val2>=10 and val2<=18:\n",
        "    predicted_cat.append(\"mild\")\n",
        "  elif val2>=19 and val2<=29:\n",
        "    predicted_cat.append(\"moderate\")\n",
        "  else:\n",
        "    predicted_cat.append(\"severe\")\n",
        "\n",
        "\n",
        "  \n",
        "print(correct_count)\n",
        "print(\"average % of correct responses: \", 100*np.mean(np.asarray(correct_count))/21.)\n",
        "\n",
        "abs_depression = np.absolute(np.array(depression_level_truth) - np.array(depression_level_predicted))\n",
        "print(\"absolute difference in deprresion level ranging (0,63) : \",abs_depression)\n",
        "print(\"average absolute difference: \", np.mean(abs_depression))\n",
        "\n",
        "\n",
        "# for i in y_preds:\n",
        "#   print(i)\n",
        "# print()  \n",
        "# for key in test_users:\n",
        "#   print(test_users[key][\"RESPONSES\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASocgUr-jn49"
      },
      "source": [
        "text = []\n",
        "responses=[]\n",
        "t=\"\"\n",
        "for key in testing_users:\n",
        "  \n",
        "\n",
        "  for dic in testing_users[key][\"WRITINGS\"]:\n",
        "    t = dic[\"TITLE\"] + dic[\"TEXT\"]\n",
        "    text.append(t)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2GpaSEuSS8k"
      },
      "source": [
        "nparr=[[]]\n",
        "for i in range(len(text)):\n",
        "\n",
        "  arr = np.asarray([[text[i]]])\n",
        "  arr = np.append( arr, [])\n",
        "  nparr.append(arr)\n",
        "nparr\n",
        "df = pd.DataFrame(nparr, columns=['Text'])\n",
        "df = df.drop(df.index[0])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKPnNHJ4SuUB"
      },
      "source": [
        "test_x = tokenizer(\n",
        "    text = df['Text'].to_list(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=max_length,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = False,\n",
        "    verbose = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AL60LSd6S1Q8"
      },
      "source": [
        "preds = model.predict(test_x[\"input_ids\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8ZitC-bWh8I"
      },
      "source": [
        "len(preds[\"q1\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBOLjb0LUu-h"
      },
      "source": [
        "\n",
        "count = 0\n",
        "y_preds = np.zeros([80,21])\n",
        "for i,key in enumerate(testing_users):\n",
        "\n",
        "    for k in range(1,22):\n",
        "      q = preds[\"q\"+str(k)][count : count+len(testing_users[key][\"WRITINGS\"])]\n",
        "      q = np.asarray(q)\n",
        "      q = np.mean(q, axis = 0)\n",
        "\n",
        "      y_preds[i][k-1] = np.argmax(q)\n",
        "    count += len(testing_users[key][\"WRITINGS\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4lMYTJ6Xu99"
      },
      "source": [
        "y_preds = [[str(i) for i in item] for item in y_preds]\n",
        "\n",
        "for i in range(80):\n",
        "  for j in range(21):\n",
        "    val = y_preds[i][j]\n",
        "    if j!=15 and j!=17:\n",
        "      if val == '0.0':\n",
        "        y_preds[i][j] = '0'\n",
        "      elif val == '1.0':\n",
        "        y_preds[i][j] = '1'\n",
        "      elif val == '2.0':\n",
        "        y_preds[i][j] = '2'\n",
        "      elif val == '3.0':\n",
        "        y_preds[i][j]='3'\n",
        "    else:\n",
        "      if val == '0.0':\n",
        "        y_preds[i][j] = '0'\n",
        "      elif val == '1.0':\n",
        "        y_preds[i][j] = '1a'\n",
        "      elif val == '2.0':\n",
        "        y_preds[i][j] = '1b'\n",
        "      elif val == '3.0':\n",
        "        y_preds[i][j]='2a'\n",
        "      elif val == '4.0':\n",
        "        y_preds[i][j]='2b'\n",
        "      elif val == '5.0':\n",
        "        y_preds[i][j]='3a'\n",
        "      elif val == '6.0':\n",
        "        y_preds[i][j]='3b'\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSB0aSKdcOZH"
      },
      "source": [
        "len(testing_users)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdPO8H9lcDP1"
      },
      "source": [
        "i = 0\n",
        "for key in testing_users:\n",
        "  testing_users[key][\"RESPONSES\"] = y_preds[i]\n",
        "  i=i +1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TokZ0C1ec1x7"
      },
      "source": [
        "filepath = f\"/content/drive/MyDrive/Colab Notebooks/ftp/task3/results/Depression Questionnaires_anon.txt\"\n",
        "with open(filepath, \"w+\") as f:\n",
        "    f.write('\\n'.join([user + ' ' + ' '.join(testing_users[user]['RESPONSES']) for user in testing_users]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}